# easyspark

Does your big data project has multiple data sources ?
Do you use spark for distributed processing ?

If yes, this framework can help you (Once it is completed)

# Motivation
To ease the integration of reading various data sources in spark using simple configuration files
Using the config of any data source like hbase, cassandra, elastic search, mongodb or raw files ->
easyspark will give you an RDD by reading the sources.
Job done!
You just then have to write the process part of your business logic treating every data source as an RDD :)

Don't need to worry about writing/searcing the boiler plate code to convert a data source to RDD!
More to come soon. Stay tuned!
